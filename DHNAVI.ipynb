{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DHNAVI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "image_size = 64\n",
        "DATA_DIR = 'C:\\Users\\kishore kumar\\Desktop\\Dhanavi\\archive(1)\\train\\Final Train Dataset'\n",
        "X_train = np.load(DATA_DIR)\n",
        "print(f\"Shape of training data: {X_train.shape}\")\n",
        "print(f\"Data type: {type(X_train)}\")\n",
        "\n",
        "\n",
        "data = X_train.astype(np.float64)\n",
        "data = 255 * data\n",
        "X_train = data.astype(np.uint8)\n",
        "random_image = random.randint(0, len(X_train))\n",
        "plt.imshow(X_train[random_image])\n",
        "plt.title(f\"Training example #{random_image}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oa451U5VoE-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        image = self.X[index]\n",
        "        X = self.transform(image)\n",
        "        return X"
      ],
      "metadata": {
        "id": "x7yljj3LpRvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(images, nmax=64):\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid((images.detach()[:nmax]), nrow=8).permute(1, 2, 0))def show_batch(dl, nmax=64):\n",
        "    for images in dl:\n",
        "        show_images(images, nmax)\n",
        "        break"
      ],
      "metadata": {
        "id": "xftIY-AYpWzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_batch(train_dl)"
      ],
      "metadata": {
        "id": "I0SWUoAppZBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL \n",
        "from data import *\n",
        "from utils.augmentations import SSDAugmentation\n",
        "from layers.modules import MultiBoxLoss\n",
        "from ssd import build_ssd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "\n",
        "def str2bool(v):\n",
        "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(\n",
        "    description='Single Shot MultiBox Detector Training With Pytorch')\n",
        "train_set = parser.add_mutually_exclusive_group()\n",
        "parser.add_argument('--dataset', default='VOC', choices=['VOC', 'COCO'],\n",
        "                    type=str, help='VOC or COCO')\n",
        "parser.add_argument('--dataset_root', default=VOC_ROOT,\n",
        "                    help='Dataset root directory path')\n",
        "parser.add_argument('--basenet', default='vgg16_reducedfc.pth',\n",
        "                    help='Pretrained base model')\n",
        "parser.add_argument('--batch_size', default=32, type=int,\n",
        "                    help='Batch size for training')\n",
        "parser.add_argument('--resume', default=None, type=str,\n",
        "                    help='Checkpoint state_dict file to resume training from')\n",
        "parser.add_argument('--start_iter', default=0, type=int,\n",
        "                    help='Resume training at this iter')\n",
        "parser.add_argument('--num_workers', default=4, type=int,\n",
        "                    help='Number of workers used in dataloading')\n",
        "parser.add_argument('--cuda', default=True, type=str2bool,\n",
        "                    help='Use CUDA to train model')\n",
        "parser.add_argument('--lr', '--learning-rate', default=1e-3, type=float,\n",
        "                    help='initial learning rate')\n",
        "parser.add_argument('--momentum', default=0.9, type=float,\n",
        "                    help='Momentum value for optim')\n",
        "parser.add_argument('--weight_decay', default=5e-4, type=float,\n",
        "                    help='Weight decay for SGD')\n",
        "parser.add_argument('--gamma', default=0.1, type=float,\n",
        "                    help='Gamma update for SGD')\n",
        "parser.add_argument('--visdom', default=True, type=str2bool,\n",
        "                    help='Use visdom for loss visualization')\n",
        "parser.add_argument('--save_folder', default='weights/',\n",
        "                    help='Directory for saving checkpoint models')\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    if args.cuda:\n",
        "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "    if not args.cuda:\n",
        "        print(\"WARNING: It looks like you have a CUDA device, but aren't \" +\n",
        "              \"using CUDA.\\nRun with --cuda for optimal training speed.\")\n",
        "        torch.set_default_tensor_type('torch.FloatTensor')\n",
        "else:\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "\n",
        "if not os.path.exists(args.save_folder):\n",
        "    os.mkdir(args.save_folder)\n",
        "\n",
        "\n",
        "def train():\n",
        "    if args.dataset == 'COCO':\n",
        "        if args.dataset_root == VOC_ROOT:\n",
        "            if not os.path.exists(COCO_ROOT):\n",
        "                parser.error('Must specify dataset_root if specifying dataset')\n",
        "            print(\"WARNING: Using default COCO dataset_root because \" +\n",
        "                  \"--dataset_root was not specified.\")\n",
        "            args.dataset_root = COCO_ROOT\n",
        "        cfg = coco\n",
        "        dataset = COCODetection(root=args.dataset_root,\n",
        "                                transform=SSDAugmentation(cfg['min_dim'],\n",
        "                                                          MEANS))\n",
        "    elif args.dataset == 'VOC':\n",
        "        if args.dataset_root == COCO_ROOT:\n",
        "            parser.error('Must specify dataset if specifying dataset_root')\n",
        "        cfg = voc\n",
        "        dataset = VOCDetection(root=args.dataset_root,\n",
        "                               transform=SSDAugmentation(cfg['min_dim'],\n",
        "                                                         MEANS))\n",
        "\n",
        "    if args.visdom:\n",
        "        import visdom\n",
        "        global viz\n",
        "        viz = visdom.Visdom()\n",
        "\n",
        "    ssd_net = build_ssd('train', cfg['min_dim'], cfg['num_classes'])\n",
        "    net = ssd_net\n",
        "\n",
        "    if args.cuda:\n",
        "        net = torch.nn.DataParallel(ssd_net)\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "    if args.resume:\n",
        "        print('Resuming training, loading {}...'.format(args.resume))\n",
        "        ssd_net.load_weights(args.resume)\n",
        "    else:\n",
        "        vgg_weights = torch.load(args.save_folder + args.basenet)\n",
        "        print('Loading base network...')\n",
        "        ssd_net.vgg.load_state_dict(vgg_weights)\n",
        "\n",
        "    if args.cuda:\n",
        "        net = net.cuda()\n",
        "\n",
        "    if not args.resume:\n",
        "        print('Initializing weights...')\n",
        "        # initialize newly added layers' weights with xavier method\n",
        "        ssd_net.extras.apply(weights_init)\n",
        "        ssd_net.loc.apply(weights_init)\n",
        "        ssd_net.conf.apply(weights_init)\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum,\n",
        "                          weight_decay=args.weight_decay)\n",
        "    criterion = MultiBoxLoss(cfg['num_classes'], 0.5, True, 0, True, 3, 0.5,\n",
        "                             False, args.cuda)\n",
        "\n",
        "    net.train()\n",
        "    # loss counters\n",
        "    loc_loss = 0\n",
        "    conf_loss = 0\n",
        "    epoch = 0\n",
        "    print('Loading the dataset...')\n",
        "\n",
        "    epoch_size = len(dataset) // args.batch_size\n",
        "    print('Training SSD on:', dataset.name)\n",
        "    print('Using the specified args:')\n",
        "    print(args)\n",
        "\n",
        "    step_index = 0\n",
        "\n",
        "    if args.visdom:\n",
        "        vis_title = 'SSD.PyTorch on ' + dataset.name\n",
        "        vis_legend = ['Loc Loss', 'Conf Loss', 'Total Loss']\n",
        "        iter_plot = create_vis_plot('Iteration', 'Loss', vis_title, vis_legend)\n",
        "        epoch_plot = create_vis_plot('Epoch', 'Loss', vis_title, vis_legend)\n",
        "\n",
        "    data_loader = data.DataLoader(dataset, args.batch_size,\n",
        "                                  num_workers=args.num_workers,\n",
        "                                  shuffle=True, collate_fn=detection_collate,\n",
        "                                  pin_memory=True)\n",
        "    # create batch iterator\n",
        "    batch_iterator = iter(data_loader)\n",
        "    for iteration in range(args.start_iter, cfg['max_iter']):\n",
        "        if args.visdom and iteration != 0 and (iteration % epoch_size == 0):\n",
        "            update_vis_plot(epoch, loc_loss, conf_loss, epoch_plot, None,\n",
        "                            'append', epoch_size)\n",
        "            # reset epoch loss counters\n",
        "            loc_loss = 0\n",
        "            conf_loss = 0\n",
        "            epoch += 1\n",
        "\n",
        "        if iteration in cfg['lr_steps']:\n",
        "            step_index += 1\n",
        "            adjust_learning_rate(optimizer, args.gamma, step_index)\n",
        "\n",
        "        # load train data\n",
        "\n",
        "        try:\n",
        "            images, targets = next(batch_iterator)\n",
        "        except StopIteration:\n",
        "            batch_iterator = iter(data_loader)\n",
        "            images, targets = next(batch_iterator)\n",
        "\n",
        "        if args.cuda:\n",
        "            images = Variable(images.cuda())\n",
        "            targets = [Variable(ann.cuda(), volatile=True) for ann in targets]\n",
        "        else:\n",
        "            images = Variable(images)\n",
        "            targets = [Variable(ann, volatile=True) for ann in targets]\n",
        "        # forward\n",
        "        t0 = time.time()\n",
        "        out = net(images)\n",
        "        # backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss_l, loss_c = criterion(out, targets)\n",
        "        loss = loss_l + loss_c\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        t1 = time.time()\n",
        "        loc_loss += loss_l.item()\n",
        "        conf_loss += loss_c.item()\n",
        "\n",
        "        if iteration % 10 == 0:\n",
        "            print('timer: %.4f sec.' % (t1 - t0))\n",
        "            print('iter ' + repr(iteration) + ' || Loss: %.4f ||' % (loss.item()), end=' ')\n",
        "\n",
        "        if args.visdom:\n",
        "            update_vis_plot(iteration, loss_l.item(), loss_c.item(),\n",
        "                            iter_plot, epoch_plot, 'append')\n",
        "\n",
        "        if iteration != 0 and iteration % 5000 == 0:\n",
        "            print('Saving state, iter:', iteration)\n",
        "            torch.save(ssd_net.state_dict(), 'weights/ssd300_COCO_' +\n",
        "                       repr(iteration) + '.pth')\n",
        "    torch.save(ssd_net.state_dict(),\n",
        "               args.save_folder + '' + args.dataset + '.pth')\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, gamma, step):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every\n",
        "        specified step\n",
        "    # Adapted from PyTorch Imagenet example:\n",
        "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
        "    \"\"\"\n",
        "    lr = args.lr * (gamma ** (step))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def xavier(param):\n",
        "    init.xavier_uniform(param)\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        xavier(m.weight.data)\n",
        "        m.bias.data.zero_()\n",
        "\n",
        "\n",
        "def create_vis_plot(_xlabel, _ylabel, _title, _legend):\n",
        "    return viz.line(\n",
        "        X=torch.zeros((1,)).cpu(),\n",
        "        Y=torch.zeros((1, 3)).cpu(),\n",
        "        opts=dict(\n",
        "            xlabel=_xlabel,\n",
        "            ylabel=_ylabel,\n",
        "            title=_title,\n",
        "            legend=_legend\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def update_vis_plot(iteration, loc, conf, window1, window2, update_type,\n",
        "                    epoch_size=1):\n",
        "    viz.line(\n",
        "        X=torch.ones((1, 3)).cpu() * iteration,\n",
        "        Y=torch.Tensor([loc, conf, loc + conf]).unsqueeze(0).cpu() / epoch_size,\n",
        "        win=window1,\n",
        "        update=update_type\n",
        "    )\n",
        "    # initialize epoch plot on first iteration\n",
        "    if iteration == 0:\n",
        "        viz.line(\n",
        "            X=torch.zeros((1, 3)).cpu(),\n",
        "            Y=torch.Tensor([loc, conf, loc + conf]).unsqueeze(0).cpu(),\n",
        "            win=window2,\n",
        "            update=True\n",
        "        )\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "metadata": {
        "id": "5tMyM7WLn7fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-nRHAiynz_p"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from data import VOC_ROOT, VOC_CLASSES as labelmap\n",
        "from PIL import Image\n",
        "from data import VOCAnnotationTransform, VOCDetection, BaseTransform, VOC_CLASSES\n",
        "import torch.utils.data as data\n",
        "from ssd import build_ssd\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Single Shot MultiBox Detection')\n",
        "parser.add_argument('--trained_model', default='weights/ssd_300_VOC0712.pth',\n",
        "                    type=str, help='Trained state_dict file path to open')\n",
        "parser.add_argument('--save_folder', default='eval/', type=str,\n",
        "                    help='Dir to save results')\n",
        "parser.add_argument('--visual_threshold', default=0.6, type=float,\n",
        "                    help='Final confidence threshold')\n",
        "parser.add_argument('--cuda', default=True, type=bool,\n",
        "                    help='Use cuda to train model')\n",
        "parser.add_argument('--voc_root', default=VOC_ROOT, help='Location of VOC root directory')\n",
        "parser.add_argument('-f', default=None, type=str, help=\"Dummy arg so we can load in Jupyter Notebooks\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "if args.cuda and torch.cuda.is_available():\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "else:\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "\n",
        "if not os.path.exists(args.save_folder):\n",
        "    os.mkdir(args.save_folder)\n",
        "\n",
        "\n",
        "def test_net(save_folder, net, cuda, testset, transform, thresh):\n",
        "    # dump predictions and assoc. ground truth to text file for now\n",
        "    filename = save_folder+'test1.txt'\n",
        "    num_images = len(testset)\n",
        "    for i in range(num_images):\n",
        "        print('Testing image {:d}/{:d}....'.format(i+1, num_images))\n",
        "        img = testset.pull_image(i)\n",
        "        img_id, annotation = testset.pull_anno(i)\n",
        "        x = torch.from_numpy(transform(img)[0]).permute(2, 0, 1)\n",
        "        x = Variable(x.unsqueeze(0))\n",
        "\n",
        "        with open(filename, mode='a') as f:\n",
        "            f.write('\\nGROUND TRUTH FOR: '+img_id+'\\n')\n",
        "            for box in annotation:\n",
        "                f.write('label: '+' || '.join(str(b) for b in box)+'\\n')\n",
        "        if cuda:\n",
        "            x = x.cuda()\n",
        "\n",
        "        y = net(x)      # forward pass\n",
        "        detections = y.data\n",
        "        # scale each detection back up to the image\n",
        "        scale = torch.Tensor([img.shape[1], img.shape[0],\n",
        "                             img.shape[1], img.shape[0]])\n",
        "        pred_num = 0\n",
        "        for i in range(detections.size(1)):\n",
        "            j = 0\n",
        "            while detections[0, i, j, 0] >= 0.6:\n",
        "                if pred_num == 0:\n",
        "                    with open(filename, mode='a') as f:\n",
        "                        f.write('PREDICTIONS: '+'\\n')\n",
        "                score = detections[0, i, j, 0]\n",
        "                label_name = labelmap[i-1]\n",
        "                pt = (detections[0, i, j, 1:]*scale).cpu().numpy()\n",
        "                coords = (pt[0], pt[1], pt[2], pt[3])\n",
        "                pred_num += 1\n",
        "                with open(filename, mode='a') as f:\n",
        "                    f.write(str(pred_num)+' label: '+label_name+' score: ' +\n",
        "                            str(score) + ' '+' || '.join(str(c) for c in coords) + '\\n')\n",
        "                j += 1\n",
        "\n",
        "\n",
        "def test_voc():\n",
        "    # load net\n",
        "    num_classes = len(VOC_CLASSES) + 1 # +1 background\n",
        "    net = build_ssd('test', 300, num_classes) # initialize SSD\n",
        "    net.load_state_dict(torch.load(args.trained_model))\n",
        "    net.eval()\n",
        "    print('Finished loading model!')\n",
        "    # load data\n",
        "    testset = VOCDetection(args.voc_root, [('2007', 'test')], None, VOCAnnotationTransform())\n",
        "    if args.cuda:\n",
        "        net = net.cuda()\n",
        "        cudnn.benchmark = True\n",
        "    # evaluation\n",
        "    test_net(args.save_folder, net, args.cuda, testset,\n",
        "             BaseTransform(net.size, (104, 117, 123)),\n",
        "             thresh=args.visual_threshold)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    test_voc()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_mislabeled_images(class_names, test_images, test_labels, pred_labels):\n",
        "    \"\"\"\n",
        "        Print 25 examples of mislabeled images by the classifier, e.g when test_labels != pred_labels\n",
        "    \"\"\"\n",
        "    BOO = (test_labels == pred_labels)\n",
        "    mislabeled_indices = np.where(BOO == 0)\n",
        "    mislabeled_images = test_images[mislabeled_indices]\n",
        "    mislabeled_labels = pred_labels[mislabeled_indices]\n",
        "\n",
        "    title = \"Some examples of mislabeled images by the classifier:\"\n",
        "    display_examples(class_names,  mislabeled_images, mislabeled_labels)\n",
        "\n",
        "print_mislabeled_images(class_names, test_images, test_labels, pred_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "gEyU_XjfvkKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CM = confusion_matrix(test_labels, pred_labels)\n",
        "ax = plt.axes()\n",
        "sn.heatmap(CM, annot=True, \n",
        "           annot_kws={\"size\": 10}, \n",
        "           xticklabels=class_names, \n",
        "           yticklabels=class_names, ax = ax)\n",
        "ax.set_title('Confusion matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MKQixtadvnmk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}